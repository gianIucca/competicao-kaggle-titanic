{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20b5e70a",
   "metadata": {},
   "source": [
    "# Esse notebook é uma continuação do Competição Kaggle - Titanic - Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d93361e",
   "metadata": {},
   "source": [
    "## Dentro desse segundo caderno, vamos começar a desenvolver o modelo de machine learning e criar o dataframe para submissão do desafio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "6cf3b072",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criação e manipulação dos dataframes\n",
    "import pandas as pd \n",
    "\n",
    "#Operações matemáticas\n",
    "import numpy as np \n",
    "\n",
    "#Técnica de dimensionalidade \n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#Biblioteca de normalização\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "#Biblioteca de clusterização\n",
    "from sklearn.cluster import KMeans, MeanShift\n",
    "\n",
    "#Classificadores\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Separar os dataframes em treino e teste\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Métricas de qualidade do modelo \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Verificar o run time dos modelos\n",
    "from time import time\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57611726",
   "metadata": {},
   "source": [
    "## Importando os dados e realizando o tratamento deles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "020a3e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('Data/train.csv')\n",
    "df_test = pd.read_csv('Data/test.csv')\n",
    "\n",
    "def limpar_dataframe(df):\n",
    "    #Criando a nova coluna somando os irmãos/conjugues e pais/filhos\n",
    "    df['Tamanho_Familia'] = df['SibSp'] + df['Parch']\n",
    "    \n",
    "    #Criando uma nova coluna para verificar quem estava sozinho\n",
    "    df['Sozinho'] = df['Tamanho_Familia'].apply(lambda x: 1 if x == 0 else 0)\n",
    "    \n",
    "    #Completando os valores de embarque com a moda da coluna\n",
    "    df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n",
    "    \n",
    "    #Completando os valores de idade e preço com a mediana da coluna\n",
    "    df['Age'].fillna(df['Age'].median(), inplace=True)\n",
    "    df['Fare'].fillna(df['Fare'].median(), inplace=True)\n",
    "    \n",
    "    #Pegando apenas a letra da cabine\n",
    "    df['Letra_Cabine'] = df['Cabin'].str[:1]\n",
    "    \n",
    "    #Criando uma coluna com apenas o titulo da pessoa\n",
    "    df['Titulo'] = df['Name'].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]\n",
    "    #Pegando os titulos mais comuns e retirando o resto\n",
    "    titulos = df['Titulo'].value_counts(ascending=False)[:4]\n",
    "    #Deixando os titulos com poucos valores como Misc\n",
    "    df['Titulo'] = df['Titulo'].apply(lambda x: x if x in titulos else 'Misc')\n",
    "    \n",
    "    #Transformando as colunas categóricas em numéricas\n",
    "    #df = pd.get_dummies(df, columns=['Sex', 'Embarked', 'Letra_Cabine', 'Titulo'])\n",
    "    \n",
    "    #Removendo as colunas que não serão necessárias\n",
    "    df.drop(columns=['PassengerId', 'Cabin', 'Name', 'Ticket'], inplace=True)\n",
    "    \n",
    "limpar_dataframe(df_train)\n",
    "limpar_dataframe(df_test)\n",
    "\n",
    "df_train = pd.get_dummies(df_train, columns=['Titulo', 'Embarked', 'Sex', 'Letra_Cabine'])\n",
    "df_test = pd.get_dummies(df_test, columns=['Titulo', 'Embarked', 'Sex', 'Letra_Cabine'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273c21ee",
   "metadata": {},
   "source": [
    "## Separando em treino/teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "662b2bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop(columns=['Survived'])\n",
    "y = df_train['Survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f025f6fd",
   "metadata": {},
   "source": [
    "## Testando os diferentes classificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "dd0189a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pc\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nome</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>1.247144</td>\n",
       "      <td>{'verbose': 0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.073017</td>\n",
       "      <td>{'objective': 'binary:logistic', 'use_label_en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.127050</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.444064</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0001, 'batch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.105620</td>\n",
       "      <td>{'bootstrap': False, 'ccp_alpha': 0.0, 'class_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.021002</td>\n",
       "      <td>{'base_estimator': None, 'bootstrap': True, 'b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.770950</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>{'priors': None, 'var_smoothing': 1e-09}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.765363</td>\n",
       "      <td>0.004001</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.664804</td>\n",
       "      <td>0.034003</td>\n",
       "      <td>{'C': 1.0, 'break_ties': False, 'cache_size': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>0.486034</td>\n",
       "      <td>0.003002</td>\n",
       "      <td>{'alpha': 0.0001, 'class_weight': None, 'early...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Nome  Accuracy  Run Time  \\\n",
       "9      CatBoostClassifier  0.826816  1.247144   \n",
       "8           XGBClassifier  0.810056  0.073017   \n",
       "0  RandomForestClassifier  0.804469  0.127050   \n",
       "4           MLPClassifier  0.804469  0.444064   \n",
       "2    ExtraTreesClassifier  0.798883  0.105620   \n",
       "1       BaggingClassifier  0.782123  0.021002   \n",
       "6              GaussianNB  0.770950  0.003000   \n",
       "7  DecisionTreeClassifier  0.765363  0.004001   \n",
       "5                     SVC  0.664804  0.034003   \n",
       "3              Perceptron  0.486034  0.003002   \n",
       "\n",
       "                                          Parameters  \n",
       "9                                     {'verbose': 0}  \n",
       "8  {'objective': 'binary:logistic', 'use_label_en...  \n",
       "0  {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...  \n",
       "4  {'activation': 'relu', 'alpha': 0.0001, 'batch...  \n",
       "2  {'bootstrap': False, 'ccp_alpha': 0.0, 'class_...  \n",
       "1  {'base_estimator': None, 'bootstrap': True, 'b...  \n",
       "6           {'priors': None, 'var_smoothing': 1e-09}  \n",
       "7  {'ccp_alpha': 0.0, 'class_weight': None, 'crit...  \n",
       "5  {'C': 1.0, 'break_ties': False, 'cache_size': ...  \n",
       "3  {'alpha': 0.0001, 'class_weight': None, 'early...  "
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [\n",
    "    RandomForestClassifier(),\n",
    "    BaggingClassifier(),\n",
    "    ExtraTreesClassifier(),\n",
    "    Perceptron(),\n",
    "    MLPClassifier(),\n",
    "    SVC(),\n",
    "    GaussianNB(),\n",
    "    DecisionTreeClassifier(),\n",
    "    XGBClassifier(),\n",
    "    CatBoostClassifier(verbose=0)\n",
    "]\n",
    "\n",
    "accuracy = []\n",
    "name = []\n",
    "parameters = []\n",
    "tempo = []\n",
    "\n",
    "for model in models:\n",
    "    \n",
    "    tempo_inicial = time()\n",
    "    \n",
    "    clf = model.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    accuracy.append(accuracy_score(y_test, y_pred))\n",
    "    name.append(model.__class__.__name__)\n",
    "    parameters.append(model.get_params())\n",
    "    \n",
    "    tempo_final = time() - tempo_inicial\n",
    "    tempo.append(tempo_final)\n",
    "    \n",
    "resultado = pd.DataFrame({'Nome': name,\n",
    "                         'Accuracy': accuracy,\n",
    "                         'Run Time': tempo,\n",
    "                         'Parameters': parameters})\n",
    "\n",
    "resultado.sort_values(by='Accuracy', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
